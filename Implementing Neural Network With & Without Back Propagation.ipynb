{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1FxIohQ0Xsh"
   },
   "source": [
    "# Implementing Neural Network With & Without Back Propagation\n",
    "## Name: Tejas Yogesh Pawar\n",
    "#### ======================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AIM :** Write a Program to implement neural network with and without back propagation.\n",
    "\n",
    "**PACKAGES :** conx , calysto\n",
    "\n",
    "**DESCRIPTION :** Backpropagation is the essence of neural network training. It is the method of\n",
    "fine-tuning the weights of a neural network based on the error rate obtained in the previous\n",
    "epoch (i.e., iteration). Proper tuning of the weights allows you to reduce error rates and make the\n",
    "model reliable by increasing its generalization. Backpropagation in neural network is a short\n",
    "form for “backward propagation of errors.” It is a standard method of training artificial neural\n",
    "networks. This method helps calculate the gradient of a loss function with respect to all the\n",
    "weights in the network.\n",
    "\n",
    "**ALGORITHM :**\n",
    "1. Inputs X, arrive through the preconnected path\n",
    "2. Input is modeled using real weights W. The weights are usually randomly selected.\n",
    "3. Calculate the output for every neuron from the input layer, to the hidden layers, to the\n",
    "output layer.\n",
    "4. Calculate the error in the outputs\n",
    "5. Travel back from the output layer to the hidden layer to adjust the weights such that the\n",
    "error is decreased. Keep repeating the process until the desired output is achieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOpZeZoudvqL"
   },
   "source": [
    "### With BackPropagation Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NnG1WC-VsnO",
    "outputId": "2d5170b1-2994-4819-d2bd-95d1904050e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline\n",
    "\n",
    "data = loadmat('/content/ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsoOtVtPVsnU"
   },
   "source": [
    "Since we're going to need these later (and will use them often), let's create some useful variables up-front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gK8LISEvVsnV",
    "outputId": "9d0aab95-107f-482f-dcb4-5c399a21a43a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX3OTcgJVsnX"
   },
   "source": [
    "We're also going to need to one-hot encode our y labels.  One-hot encoding turns a class label n (out of k classes) into a vector of length k where index n is \"hot\" (1) while the rest are zero.  Scikit-learn has a built in utility we can use for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDPZCocZVsnY",
    "outputId": "189b58a1-cbed-4c32-ac70-3676feb14163"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XVsbW-sVsna",
    "outputId": "e791f054-e6e5-4150-b8e9-70ed2a483787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10], dtype=uint8), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], y_onehot[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SRxGouAVsnc"
   },
   "source": [
    "The neural network we're going to build for this exercise has an input layer matching the size of our instance data (400 + the bias unit), a hidden layer with 25 units (26 with the bias unit), and an output layer with 10 units corresponding to our one-hot encoding for the class labels.  For additional details and an image of the network architecture, please refer to the PDF in the \"exercises\" folder.\n",
    "\n",
    "The first piece we need to implement is a cost function to evaluate the loss for a given set of network parameters.  The source mathematical function is in the exercise text (and looks pretty intimidating).  Here are the functions required to compute the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "YQdQ6QFtVsne"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "aAVYH8fGVsnf"
   },
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "0mv3kmz5Vsnh"
   },
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMfG9zuKVsnj"
   },
   "source": [
    "We've used the sigmoid function before so that's not new.  The forward-propagate function computes the hypothesis for each training instance given the current parameters.  It's output shape should match the same of our one-hot encoding for y.  We can test this real quick to convince ourselves that it's working as expected (the intermediate steps are also returned as these will be useful later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVGW7YbiVsnk",
    "outputId": "b99713b9-c4c2-4ff1-bb80-6a7921559701"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 401), (10, 26))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = 400\n",
    "hidden_size = 25\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = X.shape[0]\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErG11ZE0Vsnl",
    "outputId": "242eb8db-26ea-4454-e5ee-1ec51cbb406d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 25), (5000, 26), (5000, 10), (5000, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmqg2t2RVsnm"
   },
   "source": [
    "The cost function, after computing the hypothesis matrix h, applies the cost equation to compute the total error between y and h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVc1LRcpVsnn",
    "outputId": "c60ac9fe-e0dd-4439-9257-e4fb39f6ae72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.454224624916233"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vdiBr5gVsno"
   },
   "source": [
    "Our next step is to add regularization to the cost function.  If you're following along in the exercise text and thought the last equation looked ugly, this one looks REALLY ugly.  It's actually not as complicated as it looks though - in fact, the regularization term is simply an addition to the cost we already computed.  Here's the revised cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "VkoLA8r_Vsno"
   },
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xq-kuMKuVsnp",
    "outputId": "bf3fd9d5-c035-435f-8277-d37b1a7419a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.459514100013231"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75KjknUPVsnq"
   },
   "source": [
    "Next up is the backpropagation algorithm.  Backpropagation computes the parameter updates that will reduce the error of the network on the training data.  The first thing we need is a function that computes the gradient of the sigmoid function we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5LDDFCQiVsnr"
   },
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8SkAj7aVsns"
   },
   "source": [
    "Now we're ready to implement backpropagation to compute the gradients.  Since the computations required for backpropagation are a superset of those required in the cost function, we're actually going to extend the cost function to also perform backpropagation and return both the cost and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6l7Jhyw7Vsns"
   },
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F45iTA8OVsnt"
   },
   "source": [
    "The hardest part of the backprop computation (other than understanding WHY we're doing all these calculations) is getting the matrix dimensions right.  By the way, if you find it confusing when to use A * B vs. np.multiply(A, B), you're not alone.  Basically the former is a matrix multiplication and the latter is an element-wise multiplication (unless A or B is a scalar value, in which case it doesn't matter).  I wish there was a more concise syntax for this (maybe there is and I'm just not aware of it).\n",
    "\n",
    "Anyway, let's test it out to make sure the function returns what we're expecting it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4Av7zEAVsnu",
    "outputId": "a5541863-93f1-4390-a1ec-58b1bc1e0b08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.459514100013231, (10285,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy2OKrwHVsnv"
   },
   "source": [
    "We still have one more modification to make to the backprop function - adding regularization to the gradient calculations.  The final regularized version is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "-j1i6TRtVsnw"
   },
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZxxOO8AVsnx",
    "outputId": "2c9d9e42-9d6d-4683-8488-6baedd28552d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.459514100013231, (10285,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OevuwfEbVsny"
   },
   "source": [
    "We're finally ready to train our network and use it to make predictions.  This is roughly similar to the previous exercise with multi-class logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wt81Lr3kVsny",
    "outputId": "73fcd17c-5a41-482d-9b0a-6de90dbcbcd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 0.4112152344389323\n",
       "     jac: array([ 2.97705623e-04, -7.97842969e-07,  1.10906133e-05, ...,\n",
       "       -1.56928958e-04, -1.85748039e-03, -2.19914691e-03])\n",
       " message: 'Linear search failed'\n",
       "    nfev: 224\n",
       "     nit: 16\n",
       "  status: 4\n",
       " success: False\n",
       "       x: array([-0.60032943, -0.00398921,  0.05545307, ..., -0.87234584,\n",
       "        1.19304882,  0.74469011])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, X, y_onehot, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qihi1Y44Vsnz"
   },
   "source": [
    "We put a bound on the number of iterations since the objective function is not likely to completely converge.  Our total cost has dropped below 0.5 though so that's a good indicator that the algorithm is working.  Let's use the parameters it found and forward-propagate them through the network to get some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqMVuEfZVsn0",
    "outputId": "12f19d05-eb0b-40ff-c7ed-8be6d5c605c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [10],\n",
       "       [10],\n",
       "       ...,\n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.matrix(X)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyHI7JUSVsn1"
   },
   "source": [
    "Finally we can compute the accuracy to see how well our trained network is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaLnGjGqVsn1",
    "outputId": "f70bc11f-6626-482f-cc76-b6e90604b8f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 97.42%\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print('accuracy = {0}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06n5O15BVsn2"
   },
   "source": [
    "And we're done!  We've successfully implemented a rudimentary feed-forward neural network with backpropagation and used it to classify images of handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6HnrudqbBtK"
   },
   "source": [
    "### Without BackPropagation Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDsGcwfvbGBB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTIutq7ObGHN"
   },
   "outputs": [],
   "source": [
    "toNodes = range(3, 5)\n",
    "fromNodes = range(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhsZYl65bGJ8"
   },
   "outputs": [],
   "source": [
    "bias       = [0.2, -0.1, 0.5, 0.1, 0.4, 0.9]\n",
    "activation = [0.8, -0.3, -0.8, 0.1, 0.5]\n",
    "netInput   = [0, 0, 0, 0, 0]\n",
    "weight = [[ 0.1, -0.8], \n",
    "          [-0.3,  0.1], \n",
    "          [ 0.2, -0.1], \n",
    "          [ 0.0,  0.1], \n",
    "          [ 0.8, -0.8], \n",
    "          [ 0.4, 0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZ-Q3ETUbGM2",
    "outputId": "572ee060-2ff6-43f0-f52a-f43803255255"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0.07, 1.28]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in toNodes:\n",
    "    netInput[i] = bias[i]\n",
    "    for j in fromNodes:\n",
    "        netInput[i] += (weight[i][j] * activation[j]) \n",
    "netInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-krpOt-bGPZ"
   },
   "outputs": [],
   "source": [
    "def activationFunction(netInput):\n",
    "    return 1.0 / (1.0 + math.exp(-netInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdJ5IBYAbGSc",
    "outputId": "fb8a8abd-f31f-4f1c-acac-3f5514faadd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8, -0.3, -0.8, 0.5174928576663897, 0.7824497764231124]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in toNodes:\n",
    "    activation[i] = activationFunction(netInput[i])\n",
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWX-4YERbGVF"
   },
   "outputs": [],
   "source": [
    "xs = range(-10, 10)\n",
    "pts = [activationFunction(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ZKhLqME3bGYL",
    "outputId": "67fc2fb5-01dd-4702-8397-db3173a31d5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, pts)\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ObaLxHXbpDn"
   },
   "source": [
    "1.5 Learning Rule\n",
    "Backprop networks fall under the category of supervised learning schemes. That is, during training, the network is presented a training input, the inputs are propagated using the transfer function, until output appears in the output layer. The output is then compared with the expected or target output and an error is computed. The error is then backpropagated by applying the learning rule.\n",
    "\n",
    "A learning rule modifies the weights between nodes. The backpropagation algorithm, also called the generalized delta rule, systematically changes the weights by using a weight change equation. We use an optional momentum term in the weight change rule to help speed up convergence. The weight change rule is different for weights between the hidden-output layer nodes and the input-hidden layer nodes. For the hidden-output layer nodes it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE5B9kSbbGbP"
   },
   "outputs": [],
   "source": [
    "desiredOutput = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "actualOutput = [0.8, 0.6, 0.5, 0.8, 0.3]\n",
    "\n",
    "error = [0.0 for i in desiredOutput]\n",
    "delta = [0.0 for i in desiredOutput]\n",
    "\n",
    "EPSILON = 0.1   # learning rate\n",
    "MOMENTUM = 0.01 # a smoothing term\n",
    "\n",
    "weightUpdate = [[ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_fPJ9KPbGeN",
    "outputId": "c253fc28-974d-4297-9a0f-a1030e432408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [-0.00512, -0.00384],\n",
       " [0.00336, 0.0025199999999999997],\n",
       " [0.0, 0.0]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in toNodes:\n",
    "    error[i] = (desiredOutput[i] - actualOutput[i])\n",
    "    delta[i] = error[i] * actualOutput[i] * (1 - actualOutput[i])\n",
    "    for j in fromNodes:\n",
    "        weightUpdate[i][j] = (EPSILON * delta[i] * actualOutput[j]) + (MOMENTUM * weightUpdate[i][j])\n",
    "        \n",
    "weightUpdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNfYj9-ab6nu"
   },
   "source": [
    "# 2. Learning AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gmZVBYNbGhG"
   },
   "outputs": [],
   "source": [
    "from calysto.ai.conx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80r7lJPubGkX",
    "outputId": "558370a7-4d76-4814-d821-f4d999db3a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conx using seed: 1668864858.4436598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 'output': (Kind: Output, Size: 1, Active: 1, Frozen: 0)\n",
       "Target    : 0.00  \n",
       "Activation: 0.00  \n",
       "Layer 'hidden': (Kind: Hidden, Size: 3, Active: 1, Frozen: 0)\n",
       "Activation: 0.00  0.00  0.00  \n",
       "Layer 'input': (Kind: Input, Size: 2, Active: 1, Frozen: 0)\n",
       "Activation: 0.00  0.00  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "net.addLayers(2, 3, 1)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYrEMqq_bGnz",
    "outputId": "7762ed97-d53c-4476-a777-e7970c16e9c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('d', [0.508850428194075])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(input=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CX7nScIUbGra",
    "outputId": "ef6f1978-7698-4268-fb77-7d05c5cfa3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] array('d', [0.508850428194075])\n",
      "[0, 1] array('d', [0.5087996913741359])\n",
      "[1, 0] array('d', [0.5084568701392452])\n",
      "[1, 1] array('d', [0.5084048836068144])\n"
     ]
    }
   ],
   "source": [
    "for pattern in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
    "    print(pattern, net.propagate(input=pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmsnXklVdORq",
    "outputId": "6063de4e-135d-47b6-bac2-0f40190f0f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #     1 | TSS Error: 1.0716 | Correct: 0.0000 | RMS Error: 0.5176\n",
      "Epoch #     2 | TSS Error: 1.0390 | Correct: 0.0000 | RMS Error: 0.5097\n",
      "Epoch #     3 | TSS Error: 0.9007 | Correct: 0.7500 | RMS Error: 0.4745\n",
      "Epoch #     4 | TSS Error: 0.8877 | Correct: 0.7500 | RMS Error: 0.4711\n",
      "Epoch #     5 | TSS Error: 0.8294 | Correct: 0.7500 | RMS Error: 0.4554\n",
      "Epoch #     6 | TSS Error: 0.8229 | Correct: 0.7500 | RMS Error: 0.4536\n",
      "Epoch #     7 | TSS Error: 0.6941 | Correct: 0.2500 | RMS Error: 0.4166\n",
      "Epoch #     8 | TSS Error: 0.6827 | Correct: 0.0000 | RMS Error: 0.4131\n",
      "Epoch #     9 | TSS Error: 0.7093 | Correct: 0.0000 | RMS Error: 0.4211\n",
      "Epoch #    10 | TSS Error: 0.6899 | Correct: 0.0000 | RMS Error: 0.4153\n",
      "Epoch #    11 | TSS Error: 0.7038 | Correct: 0.0000 | RMS Error: 0.4195\n",
      "Epoch #    12 | TSS Error: 0.6675 | Correct: 0.2500 | RMS Error: 0.4085\n",
      "Epoch #    13 | TSS Error: 0.6200 | Correct: 0.7500 | RMS Error: 0.3937\n",
      "Epoch #    14 | TSS Error: 0.5807 | Correct: 0.2500 | RMS Error: 0.3810\n",
      "Epoch #    15 | TSS Error: 0.6190 | Correct: 0.2500 | RMS Error: 0.3934\n",
      "Epoch #    16 | TSS Error: 0.5522 | Correct: 0.2500 | RMS Error: 0.3715\n",
      "Epoch #    17 | TSS Error: 0.5560 | Correct: 0.2500 | RMS Error: 0.3728\n",
      "Epoch #    18 | TSS Error: 0.5205 | Correct: 0.2500 | RMS Error: 0.3607\n",
      "Epoch #    19 | TSS Error: 0.4629 | Correct: 0.7500 | RMS Error: 0.3402\n",
      "Epoch #    20 | TSS Error: 0.4947 | Correct: 0.2500 | RMS Error: 0.3517\n",
      "Epoch #    21 | TSS Error: 0.4871 | Correct: 0.2500 | RMS Error: 0.3490\n",
      "Epoch #    22 | TSS Error: 0.4108 | Correct: 0.2500 | RMS Error: 0.3205\n",
      "Epoch #    23 | TSS Error: 0.2906 | Correct: 0.2500 | RMS Error: 0.2695\n",
      "Epoch #    24 | TSS Error: 0.3356 | Correct: 0.7500 | RMS Error: 0.2897\n",
      "Epoch #    25 | TSS Error: 0.3023 | Correct: 0.7500 | RMS Error: 0.2749\n",
      "Epoch #    26 | TSS Error: 0.1893 | Correct: 0.7500 | RMS Error: 0.2176\n",
      "Epoch #    27 | TSS Error: 0.2453 | Correct: 0.2500 | RMS Error: 0.2476\n",
      "Epoch #    28 | TSS Error: 0.1946 | Correct: 0.2500 | RMS Error: 0.2206\n",
      "Epoch #    29 | TSS Error: 0.1487 | Correct: 0.7500 | RMS Error: 0.1928\n",
      "Epoch #    30 | TSS Error: 0.1180 | Correct: 0.7500 | RMS Error: 0.1718\n",
      "Epoch #    31 | TSS Error: 0.0995 | Correct: 0.7500 | RMS Error: 0.1577\n",
      "Epoch #    32 | TSS Error: 0.0746 | Correct: 0.7500 | RMS Error: 0.1365\n",
      "Epoch #    33 | TSS Error: 0.0606 | Correct: 0.7500 | RMS Error: 0.1231\n",
      "Epoch #    34 | TSS Error: 0.0523 | Correct: 1.0000 | RMS Error: 0.1144\n",
      "Final #    34 | TSS Error: 0.0523 | Correct: 1.0000 | RMS Error: 0.1144\n"
     ]
    }
   ],
   "source": [
    "# provide training patterns (inputs and outputs)\n",
    "net.setInputs([[0.0, 0.0],[0.0, 1.0],[1.0, 0.0],[1.0, 1.0]])\n",
    "net.setOutputs([[0.0],[0.0],[0.0],[1.0]])\n",
    "\n",
    "# set learning parameters\n",
    "net.setEpsilon(0.5)\n",
    "net.setTolerance(0.2)\n",
    "net.setReportRate(1)\n",
    "\n",
    "# learn\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nyb0BZKGdRVg",
    "outputId": "2abcd0e0-6dd1-4234-d9cd-5375c786bfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] array('d', [0.0005205208984019727])\n",
      "[0, 1] array('d', [0.07094212079625592])\n",
      "[1, 0] array('d', [0.07735037299803392])\n",
      "[1, 1] array('d', [0.8099701037161596])\n"
     ]
    }
   ],
   "source": [
    "for pattern in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
    "    print(pattern, net.propagate(input=pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0v46nkaqdX5Y"
   },
   "source": [
    "# 2.1 Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BXBFlxidefj"
   },
   "source": [
    "One of the great side benefits of using a neural network to solve a problem is that it can also do slightly different problems that it was not trained on.\n",
    "\n",
    "For example, we didn't explicitly train the network on [0.8, 0.8] for the AND problem, but we can see what the network thinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52NVzHyVdReV",
    "outputId": "1ce2f800-3ff1-407f-d0c7-365ec3e3746a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('d', [0.6397387071192325])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(input=[0.8, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "b-hQHjeodRg3",
    "outputId": "275b51f3-7ff5-4f28-d013-aa376fcba3d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEWCAYAAAB16GIqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dfdBtVX3fP7/7goY3AUnxcsFcECpFrRophaCWCo5IDYwORTBjbwgOrZMmYE0U7HSiHdPR1sbQmDC5lQilCL5GDCY6FiHViQUhEpC3iApyyeVFy3sa4cKvf+z9xH0Pa6+99tprn7PPc7+fmWeefdb67XXWPfd51vNdv993nWPujhBCtLFm0RMQQkwbLRJCiChaJIQQUbRICCGiaJEQQkTRIiGEiKJFQkwGM3vczA4eYdzXmNkdpcfdWdAiMSHM7JfN7GYz+1szu8/MLjCzvXrcf5eZHV9wPknjmdlBZvaMmV3QY+xrzOwdzTZ3393dv58z15mx3cwOaYz7dXd/8dBxd1a0SEwEM3s38GHgN4HnAUcBPwd81cx2WeTcEvhXwEPAW83sOYuejCiMu+trwV/AnsDjwKkz7bsDDwK/Uj++CPhgo/9YYGt9fQnwDPD/6rHeA2wCHDgL+BtgG/Abjft7jdcydwO+B7wTuB84Zab/ZOBG4NE67gTgt4Gngb+rx/5YHevAIcA/Be4D1jbGeTNwU319JPBN4OH63/QxYJe673/X4zxRj/3W5r+rjvlHwDX1/bcAJ828Jr8PfAl4DLgWeNGif0YW+vO56Anoy6l/cbYD6wJ9FwOX1detv9T147uA4xuPVxaJy4DdgJfVi87xOeO1zP01wE+AvYHfA/6k0Xck8AjweirVuhE4rO67BnjHzFgOHFJffw94faPvM8C59fWrqJTWuvrfeBtwTmic2X8XsB64E3gfsAvwunoxeHHjNflxPfd1wKXA5Yv+GVnkl7Yb02Bf4Efuvj3Qt63uH8IH3P0Jd78Z+ARw+sDxmmwG/szdHwI+CZxgZv+g7jsT+CN3/6q7P+Pu97r77YnjXrYyTzPbAzixbsPdb3D3/+Pu2939LuAPgX+WOO5RVArtQ+7+pLt/DbiSHV+TP3b36+r/j0uBVySOvSrRIjENfgTsa2brAn0b6v4h3NO4vhvYf+B4AJjZzwD/kuoXCXf/JvBD4G11yIFUiiCHTwJvqXMcbwH+0t3vrp/3H5rZlXVy91HgP5G+kO4P3OPuzzTa7qZSOSvc17j+W6pFZadFi8Q0+CaVZH9Ls9HMdgfeCFxVNz0B7NoIecHMOG1Heg9sXL+QKj8xZLwV3kyVT/mD+hf2Pqpfts11/z3Ai1rujY7t7rdS/fK+kWrR+WSj+wLgduBQd9+TautgHXNd4W+AA82s+bP/QuDexPt3OrRITAB3fwT4APB7ZnaCma03s03Ap4GtVElEqBKAJ5rZPmb2AuCcmaHuB0I+g/9gZrua2UuAM4BPDRxvhc3AH1HlOl5Rfx0DvNzMXgZcCJxhZseZ2Roz22hmhyWODdXCcDbwWqqcxAp7UCVCH6/He2ePeV9LpQ7eU7/OxwK/CFzeMZedl0UnRfT10y+qPfx3qCoK91Pttfdu9D+X6hf8UeAm4F3smGg8mUruPwz8Bs+ubtxHo0rRd7yZuW6kSra+LPDv+FPgI/X1m+uxH6NKGL6hbj8a+Guq0ul/q9tmE44vpKqwfGlm/NdSKYnHga8D/xH4RqP/31Dlch4GTuXZCdmXAH9OlVS9FXhzo+8iIsncnfHL6hdCrEJqNfIDYL2Hk6JCdKLthhAiihYJIUSUhSwSdXLuDjO708zOXcQcdgbc/S53N201xBDmnpMws7VUCavXU2XuvwWc7lXJSwgxMULmnbE5ErjT69N+ZnY5VRa9dZEwM2VXxeQxS7VqjD9un3vMjKeffppnnnkmeNMiFomN7OgA3Ep1oGcHzOwsqtKdWAWM9QtU6rm67kkZczYmdk9K7EpbW2yzfbat63vzes2aNTz00EOtc13EIpGEu28BtoCUxDIz9uIwZPycX/yUmJzFIbZItMUOXSTWrFnTOV9YTOLyXna0CR+ALLFCTJZFKIlvAYea2UFUi8Np/PRAkFglSEGkxcbGGENJrKiH2Bxmmfsi4e7bzezfAl8B1lIdJb5l3vMQQqSxFLZs5SSWDymJtNipKIkf//jHPPXUU5OpbohVzGpfHFISjCmxOQnMIYtEKEnZ7Iv9u2XLFkJEkZIQRZCCSIstqSBSlMSsggiVQJtbkBBSEkKIKFISIpspq4eU+/skGnPu6ZOEjN2ToyTaFERTNUzZTCWEWCKkJERvpCDifX3yDLH2HCXRpSBCJVBVN4QQg5CSEMlMWUEMrWBMRUHkKolUBaHqhhCiOFISopPVqiBKKYs+lYq2e4a4KENtXY+b11ISQohBaJEQQkTRdkO0om1G9+NYzLys1qG2tsdt2w2VQIUQ2UhJiGcxRQXR555lVhB9rNZ9EpddSiKGlIQQIoqUhABWr3qI9fVRByn3pJRAS1it++QkUpWEchJCiGykJHZypCDCbSUUxFAl0ccYlaogQkpi7dq1z/q3NZGSEEJEkZLYSZGCGK4oUq3Wsb5YniEnJ9FHSawoiK7XXUpCCBFFi4QQIoq2GzsZq3WbMcQolRIzxCgV60t5N+u2pGTOdqOZpFy5f926dSqBCiHykZLYSZCCWJzVOtSW8m7WXQoiZrFuUxDNOa1bt+7v+6QkhBDZSEmsYqaoHvrcl1PmDPWVVBA5BqnmdZeCiOUZ2pRFqG1WQax8VwlUCFEcKYlVyBQVxLJarUspiVQFEfuErT7HvtsUhKobQojiSEmsAsZWDkOeZ7UpiByrdawvlmfoUhCxw1ptCqKtuhFDSkIIEUVKYolZ7QpiXi7K5nWXgshxUcb6clyUIVXQpSBi1Y2F+STM7EAzu9rMbjWzW8zs7Lp9HzP7qpl9t/6+91hzEEIMZ8ztxnbg3e5+OHAU8KtmdjhwLnCVux8KXFU/FkJMlNG2G+6+DdhWXz9mZrcBG4GTgWPrsIuBa4D3jjWP1Yi2GfHY1G1GaDvQFpOy3ShxWCulrLkS20w4pm4zQvd0bTfmkpMws03AK4Frgf3qBQTgPmC/lnvOAs6ax/yEEO2MvkiY2e7A54Bz3P3R5orl7m5mHrrP3bcAW+oxgjE7E/NSD7nPtWgF0UdRtCUpYzExJVHysFasrDmrIJqqIFVBhJTESim0jVFLoGa2nmqBuNTdP183329mG+r+DcADY85BCDGM0ZSEVcvehcBt7v47ja4vApuBD9XfrxhrDquBZc8/DInJyTfEYkooiFieIVYCTVUQsQNYqeXMZt9se1NJpB4VH3O7cQzwduBmM7uxbnsf1eLwaTM7E7gbOHXEOQghBjJmdeMbQNvydNxYz7takIKIt/VRFF1GqVhsSp6hyyjVvO5SEqEDWH0qFV0Kopl/WLiZSgixOpAte2KMrSCGjD9vBTE0J9GlIFKURMz70KUg+hz7HmK1jvXNKojJVTeEEMuPlMREWO0KYogHIhaToiTa2mNKok1BxKobsUpFqoLIcVGG+toURKi6sWaNPlVcCDEALRJCiCjabiyQKW8xUu4fug0pUdYMxaZuM/pYrPtYrVPMVCWt1qGYtm1GM0m5Ms769eu13RBC5CMlsQCkIMoriKFKIlVBxNRBiplqDKt187pLQTTHX79+/d/HSEkIIbKRkpgjU1YQU7da9ylndsUMsVjHlETMTJWqIHKs1pCuIFbUQyimDSkJIUQUKYk5IAURbxtilBqiIPpYrGN5hll1EDJGpSqIHKt1rG9WQYTUhz7BSwgxCCmJEVntCmKRVuuU/EWq1TrU1+cTttoURHP8oZ+L0fyeclirTUE01Ufqm85ISQghomiREEJE0XZjBHbGbUaJxGWfLUSsPXWbEbNYt20zQluIlMRl6jYjlIyc7es60Qnt24zQ+EpcCiEGISVRiCmrh5T7cxRGqcRlSas1DLNYdymIWFmzrczZHKdLQYTu6XtYKxQTGj+kLkJISQghokhJDGTKCmIso9S8FESfUmjMYp1ijEpVECk5iT6HtWb/wjfvyT2s1YyZHSNUAlVOQggxCCmJTKQg+sXm5he6YmIW61SrdbNtDKt1qK9NQeRYrUMxbQpCZiohRHGkJHoyRQXR556SCmIsq3VK7JDPwwjlJFIVRI7VutnXpSByrNbNmC4FIZ+EEKI4UhIdjK0chjxPCQXRJ88Qax9DQaSogxSfRMnDWrmfi5GqIHJclKFx2hSEfBJCiOJokRBCRNF2I8CUtxh97svZSsT6ShilQjEpW5Uhn4fRZZSC7m1GyMA0xmGtHKt1rE9mKiHE6EhJNJiygihV5iyRwBxitU6JTTFIpRijUq3WobY2BZFjtY71lbBah/r6mKmkJIQQgxhdSZjZWuB64F53f5OZHQRcDjwfuAF4u7s/OfY8OuY42eeZsoLItVq3KYkUg1SKMSpVQcRyEm0KIsdqHeorabVOiZm6Lfts4LbG4w8DH3X3Q4CHgDPnMAchRCajKgkzOwD4F8BvA//OquXqdcDb6pCLgfcDF4w5j8j8Jvs8izJKhfpSKhZtsSmqoM89Yx/W6lIQOVbr0P0lrdYpMSkVkTbGVhK/C7wHeKZ+/HzgYXffXj/eCmwM3WhmZ5nZ9WZ2/chzFEJEGE1JmNmbgAfc/QYzO7bv/e6+BdhSj+WF51ZyuKLPsygFket5aIstrSTGPqyVqiByrNax2BJW65SYropI7GdmzO3GMcBJZnYi8FxgT+B8YC8zW1eriQOAe0ecgxBiIKNtN9z9PHc/wN03AacBX3P3XwKuBk6pwzYDV4w1ByHEcBZhpnovcLmZfRD4NnDhPJ50XluM3Odaxm1GzhaiT2yO1brZl2q1Do1Twmodiy1ptY7FpJRNu0qgc1kk3P0a4Jr6+vvAkfN4XiHEcKKLhJntCfysu39vpv0fu/tNo86sEKs9SRnryzVKpSqIsZTEEKs1jHtYK6UEGosdw2rdJ7boO1OZ2anA7cDnzOwWM/snje6LWkcUQqwqYkrifcCr3H2bmR0JXGJm57n7HwPz2+BnIgXRLzblnhJ5hlhfCat1qK3LKNWMHWK1jsUO/VyM2L19YmNl2TZii8Rad98G4O7Xmdk/B640swOBor4FIcR0iS0Sj5nZi1byEbWiOBb4AvCSeUwuBymIfmPkVDdKK4mSVutQW8nDWrHqQ1sFIxRb0mqdEhuruAwxU72TmW2Fuz9mZicAp0buE0KsIloXCXf/q5b2p4BLR5tRJmMriCHjz9sDkaMgUqobpZRE25HwWMViKoe1cqzWzdgxrNax2FjFZUpHxYUQS8wiHJdFkYJIfxyLSclNlPA+xPpSqhuLPqyV46KMjVPCRRnrK5GT6FQSZnZ2SpsQYnWSst3YHGj75cLzEEJMlNbthpmdTvUOUgeZ2RcbXXsA/3fsicWY8hajz/05Zc5Q36K2GTkGqVBfSgl0Koe1cqzWsb4SVuuU+Y5lpvoLYBuwL/BfG+2PAUtxbkMIMZxYCfRu4G7g6PlNJ86UFcS8jVKhtj6KIqUEWtIglWKMKmG1bl6PcVhrEZ+L0fb+mCnGrpTE5eCj4mb2GD+1Ye8CrAeecPc9u+4VQiw/nYuEu++xcm3VcnMycNSYkwoxpooYW0EMiZmXgiilJLqMUqGYklbrZuwYh7Xm+bkYOeXSPjmJkKksRC8zlVd8AXhDn/uEEMtLynbjLY2Ha4AjgL8bbUZzZNEKYkgFIyUm9Jd+9nEpJZFqtQ71dRmlmm2LPqyVY7VOiRmSx4jNvy2vMRszKCcB/GLjejtwF9WWQwixE5CSkzhjHhOZJzuLgsjxQKTEhPIMXQoipjpKWq2bfWMc1so9yl3CJ9HH89CmIEY54GVmB5vZn5jZg2b2gJldYWYHd90nhFgdpCQuPwl8GtgA7A98BrhszEkJIaZDSk5iV3e/pPH4f5rZb441obEYWkIdsoVIiRlS1px9nLPN6LPdGGK1braNYbVu3jfGic6hJcoSyc4+ics2I1aor42UReLPzOxc4HIqU9VbgT81s30A3H2h5ziEEOOSskisvFXdv55pP41q0Zh0fmLKCiInKRmLSSmBDlESfd7NOqY6UhVEjtU61lfisFZuibKEmapP4rJNQbSZqQaVQN39oK4YIcTqJUVJYGa/AGxqxrv7/xhpTkVYdJkzFjPUGDXblqIshiiJPu9m3WWUCrXN/uUfYrWO9ZU4rJWjDlJihlitQ69PHzNV83UIkeK4vAR4EXAj8HTd7MCkFwkhRBlSlMQRwOHuvhQfyLNMCmJoTqJLQQxVEl3qIMdq3WzrUhA5VutQX8nDWvM0Uw05rJVipmq+zoPMVMB3gBckxAkhViEpSmJf4FYzuw74yUqju5802qwyWLSCGOKBSIkJ/aWffVxKSaQqiNg9scNaqQoix2rd7BvjsNbYPokcq3VKTEhxFatuAO9PiBFCrFJSSqB/Po+J5LLMCmKIByLUN0RJ5Hge+rgoQ6pgDBdlLHZen4sx5LBWjosyJSYlz9NG6yJhZt9w91fbjm9fB2BU7z+jt68TYiegdZFw91fX3/doixFCrH6SzFS5mNlewMeBl1KpkV8B7gA+RWXOugs41d0f6jnu0HkNHn8Zthkp240cY1Qfq3VI0s5uM2Zt2EOs1qHYeX0uRsr4Y1itYzEpyeASJdAhnA982d0PA14O3AacC1zl7ocCV9WPhRATZTQlYWbPA15L/ZGA7v4k8KSZnQwcW4ddDFwDvDdxzJx5FI1NNUqF2koYpUIxOUqijzGq7f0rc6zWzesuBZFjtW7GzvtzMfqMX9JqHYpJSQaH1EWIMZXEQcCDwCfM7Ntm9nEz2w3Yz9231TH3AfuFbjazs8zsejO7fsQ5CiE6GDMnsQ74eeDX3P1aMzufma2Fu7uZBe3e7r4F2AJgZt5XRaw2BVFKSfQxRnUpiFBOossoBekKIsdqDeMe1krJY/QpsfZRBykW6y4F0VYCXVROYiuw1d2vrR9/lmrRuN/MNgDU3x8YcQ5CiIGMpiTc/T4zu8fMXuzudwDHAbfWX5uBD9Xfryj5vItSEEMVxRhKIuXdrEOxqQqij9W6+Vc1VUHkWK1DsWMf5e5T3cixWqeopyHVjcFHxQfya8ClZrYL8H3gDCr18mkzO5PqA4lPjdwvhFgwoy4S7n4j1VHzWY4r/VwlFUSKKugT20cdtMX0URIpb1TbVsEIjTfEaj2bfwj1lbRaN2PHPsqdU93oY7XuUhBDqxtT8UkIIZYcLRJCiChj5yRGJ3WbkZukHCNx2ZakjMWkbDfaEo6hvrYyZ/N6DKt1s28Mq3VsnNJmqj4l0NRtRsoWK7Y16dpmhJKdXYlLKQkhRJSlVBJjlzlj9yxKQcSURJuCyLFaQ7qCyLFah8YpabWO9ZUwU+VYrZvXJQ1Sodiu/6vQPV2/I1ISQogoS6UkSimIPuXMtr4UY9Ts4z5mqhyLdQmrdaitpNU61lfCah3qK3lYq4/VOpZfSFESXTExM1Wbgmh7NzGVQIUQ2SyNkhhaxchRFqG+VJUQ6xtitYZ0BZFjtW62jWG1DvWVtFqnxAypVPSpWIRiSyiJrsNaoZiQulR1QwhRhKVREl2UVBA5FYuUvhJW61hfCat183oMq3WzbwyrdUrMkMNaKXmGUtWNLgUR86m0KYi26olyEkKIbJZeSUxFQfSpbgxxUcb6clyUMVXQFZvjoozFlnBRpsTkjJ+SZ4hVN4YoiTZ1EPNJtCmImPpoQ0pCCBFFi4QQIspSbjfmbZRqtg1JYJawWof6cqzWsa1DamyO1ToUW9JqnRIzpAQa2g50GaVifbF7urYZscNabdsMbTeEEMVZKiWx2hREjtU61Nb2F6H5V6lLFfSJHWK1bsaOYbVOiRlyWCulBDpEScTUQUrisktBtCkJlUCFENksjZLoqxRKWK1jfSn3jGG1brZ1KYjmPV0KIiW2hNUahn0uRlvZMaU0GRt/9vUoabVOielT1gy9pqkKImbVb0NKQggRZWmURJMpW61DbSWt1s3rLgURO4DVJ7ak1ToUO6T6MCR/EVI3Y1itY319KhZtFYxQX4qSCP1shZCSEEJEWSolMQUFUUJJDLFaz15Dt6+hed0ndgyrdTN2SPVhSHUjpm66FEQpJVHSat3s6/relttSdUMIkc1SKAkzG1zdyMkzpMQMcU/2cVGG9o1dqiDHRdns61IQOS7K2DglvA+xmBR106UghiqJPhWLNhWQEtt2r6obQojiaJEQQkRZiu3GLPO0WqduM/pYrIdYrSF969CUu6lW6+Z9Y1itY305W4iU8VO2QKnbjNztRuo2I7ZFjMWmbjNUAhVCFGeplERKObOtPUcdpMQMsVinKIkV+qiCIVbrWF8Jq3Wsr486SBm/S0HEEpclrdahtjZVEPp/7jJKhdrafp7afk5VAhVCZLM0SiKmBEJxObmJIQoix2LdZmwJxaQYZ0pYrUN9Ja3Wsb5SZqpUBZFzWCvHah1qS1F/qVbr5nWXglBOQghRnFGVhJm9C3gH4MDNwBnABuBy4PnADcDb3f3JxPE6+0ooiLEt1jFjS45xpqTVutk3htU61jfkqHhKfiSWkyihJGLGqFQFkWO1bt7fpSBiubM2RlMSZrYR+HXgCHd/KbAWOA34MPBRdz8EeAg4c6w5CCGGM3ZOYh3wM2b2FLArsA14HfC2uv9i4P3ABV0DdVUxuhREjtU61NblgQj1pdSsuxREKHYMq3UstoTVOtQ3RH2k5Ee6PBChtpJW62Zbl4Lo432I5bT6VNQWpiTc/V7gI8APqRaHR6i2Fw+7+/Y6bCuwMXS/mZ1lZteb2fXuPtY0hRAdjLnd2Bs4GTgI2B/YDTgh9X533+LuR7j7EV0rnRBiPMbcbhwP/MDdHwQws88DxwB7mdm6Wk0cANzbd+AUY9Ts41wzVeo2I5ZESrFc90lSpW4zcqzWodiSVuuUmJQtSkoStaQxKrYdSElcpm4zcgxSsZjUBPuizFQ/BI4ys12tmsFxwK3A1cApdcxm4IoR5yCEGMhoSsLdrzWzzwJ/CWwHvg1sAb4EXG5mH6zbLkwZr8tM1UcddMWklDP7lJb6mGG6jFLNccewWjdjx7Bap8TE1EdKErWtTFrCYt0ncRlTf32s1ilKNFVB5JRAR61uuPtvAb810/x94Mgxn1cIUY6lsWXD/BREbLXtU1rqk2foUhDNOaUqiFgJtMRhrVJHuVPUR5eCCP2FL3Hse/b/IcdqDekKos/PUZ+y+yRLoEKI1cHSKInUnMQQJRHLAPfJGqcqiJiSaKtghGJLWq1DsSWt1n3GTVE3ob/wJaobbQoilGdIUX+pCiL2c7RCiiro+7O9qOqGEGIVsDRKAoYpiBzvQywmlpMYoiS6PBDN6zGs1s3YEj6GnPxFirppq2CE+oZYrEtYrUOxXR6I2evQXPpU4VI8QG1ISQghoiyFkpjdM8VWwz6Oy65VNxTTx/3WR0mkuiibfWO4KGPj5PgYhhzWSskzlDr2naogUtRfLLZLQcyqh9B4Q6pwXbm9EFISQogoWiSEEFGWYruxQp/kS45BKsUYlWKRTd1m5Fitm/d1bTNyrNaxvj5mpxKHtXKs1qG2LqNUrC9mtZ79mUiJLbnNiJVAU7bSs3NrQ0pCCBFlaZREM3kZS770UQcphpNUBdFHScSs1m0JzJAqGMNqHetLMTuVPKyVY7WO9cXKmakKIpa4TIntUhCh/+c+xqgcBaESqBBiEEuvJJr9oe9ddtRQTCwnMURJxKzWXQoiVgLNsVr3MSOlmJ26FESf/MgQq3Wsr63MGerrU7ZOiU1VEDl5hljf7O9K2/iyZQshsll1SiJlRU21WjfbhiiJlDxDl4LIOawV+0vcJyfRZZSKjR/6q52qIHIqFqG2LqNU87pPRaorNvZzNDvXnDxDSp5t9vllyxZCFGcplcRsO3QriByrdfM6R0l0KYhYdaOtghGLTfEZ9Kk+dCmIPtWHUH6k63vOoa3Q65JSfeiKGWK1nr0OjTfEat12f9f4UhJCiCJokRBCRFmK7cbsVqNP6WeI1TrU1qc01rXNyLFah2JTzEh9LNap24xY4nJ2m9Fna5JzsjPF5BQzU6VuM2I/G32s1jmmv5Stw+zcUhL42m4IIQaxFEoCum3ZY1itY32x0liqggj9JStpRurzHhEph7Vi6qNLDaQYo3IObYVe/1QFkVK2TjFI5SiIlPJ7Cau1lIQQYnRWrZKIlaNSrdYpMSnlzJJWa0hXECkl0JTDWikGrD4l1lQFkWOQCvX1yS90KYgUo93snJv3dSmIHKt1SmzX745s2UKIbFadkkjZ6+UYo7oURM5hrRyrdSy2hNW6z7h9qid9qht9DFIhpTWGmSrFaDc7Vh8D3xCrdSxWOQkhxOisGiXRtVLnVCxCbSmVilQFkWO1DsX2sVq3jd/Hwt2netKnuhFTEl0KIiUnEatIpSqI0M/GCm0VjFBbSat1KLaPkuhCSkIIEWUplMSKikjJAPf5C9BHSaS6KEN9XR6IUGyJw1qxikLssFaqgkjJqfTxPKTkGVI8D6kKIvYzkeKhmX2+Pt6cki7KUFuKkmh7nlmkJIQQUbRICCGiLMV2AypJ1Me6OsQgFZKuqVbrZl/XNiOUOCt5WCsk8Ycc1kopsbZtHVLeGyKWWOzaZqQkIVPMVCW3GbESZUmjVKwvZZuh7YYQYhBLoyTWrFkTTVyWVBIp5cxYCTRVQTTnVPKwVihZWOKwVh+rdYqZqssglVLWTElCtimImCLtMkqF7kkpZ5ZUEH2UxGxc23OGkJIQQkQxd1/0HDoxsweBJ4AfLXouiezL8swVlmu+yzRXWJ75/py7/2yoYykWCQAzu97dj1j0PFJYprnCcs13meYKyzffENpuCCGiaJEQQkRZpkViy6In0INlmiss13yXaa6wfPN9FkuTkxBCLIZlUhJCiAWgRUIIEWXyi4SZnWBmd5jZnWZ27qLnM4uZHWhmV5vZrWZ2i5mdXbfvY2ZfNbPv1t/3XvRcVzCztWb2bTO7sn58kJldW7/GnzKzXRY9xxXMbC8z+6yZ3W5mtwqjPzQAAAP+SURBVJnZ0VN9bc3sXfXPwHfM7DIze+6UX9tUJr1ImNla4PeBNwKHA6eb2eGLndWz2A68290PB44CfrWe47nAVe5+KHBV/XgqnA3c1nj8YeCj7n4I8BBw5kJmFeZ84Mvufhjwcqp5T+61NbONwK8DR7j7S4G1wGlM+7VNw90n+wUcDXyl8fg84LxFz6tjzlcArwfuADbUbRuAOxY9t3ouB1D9Yr0OuBIwKkfgutBrvuC5Pg/4AXWCvdE+udcW2AjcA+xDdSbqSuANU31t+3xNWknw0xd+ha112yQxs03AK4Frgf3cfVvddR+w34KmNcvvAu8BnqkfPx942N2314+n9BofBDwIfKLeHn3czHZjgq+tu98LfAT4IbANeAS4gem+tslMfZFYGsxsd+BzwDnu/mizz6s/IwuvNZvZm4AH3P2GRc8lkXXAzwMXuPsrqc7v7LC1mNBruzdwMtXCtj+wG3DCQidViKkvEvcCBzYeH1C3TQozW0+1QFzq7p+vm+83sw11/wbggUXNr8ExwElmdhdwOdWW43xgLzNbOfc9pdd4K7DV3a+tH3+WatGY4mt7PPADd3/Q3Z8CPk/1ek/1tU1m6ovEt4BD6wzxLlSJoC8ueE47YNWh/AuB29z9dxpdXwQ219ebqXIVC8Xdz3P3A9x9E9Vr+TV3/yXgauCUOmwScwVw9/uAe8zsxXXTccCtTPC1pdpmHGVmu9Y/EytzneRr24tFJ0USEkInAn8NfA/494ueT2B+r6aSuzcBN9ZfJ1Lt9a8Cvgv8L2CfRc91Zt7HAlfW1wcD1wF3Ap8BnrPo+TXm+Qrg+vr1/QKw91RfW+ADwO3Ad4BLgOdM+bVN/ZItWwgRZerbDSHEgtEiIYSIokVCCBFFi4QQIooWCSFEFC0S4lmY2V+MMOYmM3tbpP/LZvbwyslUMR20SIhn4e6/MMKwm4DWRQL4L8DbR3heMRAtEuJZmNnj9fdjzeyaxvs5XFq7CTGzu8zsP5vZzWZ2nZkdUrdfZGanzI4FfAh4jZndaGbvmn1Od78KeGz0f5zojRYJ0cUrgXOo3s/jYKrzCCs84u4vAz5Gdbo0xrnA1939Fe7+0VFmKkZBi4To4jp33+ruz1BZzjc1+i5rfD963hMT80GLhOjiJ43rp9nxQ6Y9cL2d+ufKzNYAS/d2bWJHtEiIIby18f2b9fVdwKvq65OA9fX1Y8Aec5uZKMa67hAhWtnbzG6iUhun123/HbjCzP4K+DLVG8VAdYrz6br9otm8hJl9HTgM2N3MtgJnuvtX5vGPEHF0ClRkUb9xzRHuvgyfmC0GoO2GECKKlIQQIoqUhBAiihYJIUQULRJCiChaJIQQUbRICCGi/H+aPJ40qTzZWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.zeros((100, 100))\n",
    "\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        z[x][y] = net.propagate(input=[x/100, y/100])[0]\n",
    "\n",
    "plt.imshow(z, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.xlabel(\"input 1\")\n",
    "plt.ylabel(\"input 2\")\n",
    "plt.title(\"Output Activation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DHSO7fidp0-"
   },
   "source": [
    "We can see that the bottom, right-hand corner is white, meaning close to 1.0. However, the network has learned the surrounding area is a gradation between black (0.0) and white. We can describe this as generalization."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
